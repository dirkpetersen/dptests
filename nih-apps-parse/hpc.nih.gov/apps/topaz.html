<script type="text/javascript" language="JavaScript" src='/js/header.js'></script>
<!-- Start content - do not edit above this line  -->
<script type='text/javascript' language='JavaScript'>document.querySelector('title').textContent = 'topaz on Biowulf';</script>
<div class="title">topaz on Biowulf</div>

<table width=25% align=right>
  <tr>
    <td>
      <div class="toc">
        <div class="tocHeading">Quick Links</div>
        <div class="tocItem"><A href="#doc">Documentation</a></div>
        <div class="tocItem"><a href="#notes">Notes</a></div>
        <div class="tocItem"><a href="#int">Interactive job </a></div>
        <div class="tocItem"><a href="#sbatch">Batch job </a></div>
        <div class="tocItem"><a href="#swarm">Swarm of jobs </a></div>
      </div>
</table>

<p> Topaz is application for particle detection in cryo-electron microscopy. Topaz uses convolutional neural networks trained from positive and unlabeled examples. Topaz can also do denoising of micrographs and tomograms.</em>.  </p>

<h3>References:</h3>
<ul>
<li>Bepler, T., Morin, A., Rapp, M., Brasch, J., Shapiro, L., Noble, A.J., Berger, B.
<em><a href="https://pubmed.ncbi.nlm.nih.gov/31591578/">Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs</a></em>. Nat Methods 16, 1153â€“1160 (2019).</li>
</ul>


<a Name="doc"></a><div class="heading">Documentation</div>
<ul>
<li>topaz Main Site: <a href="https://github.com/tbepler/topaz">GitHub</a></li>
</ul>

<div class="heading">Important Notes</div>
<ul>
    <li>Module Name: topaz (see <a href="/apps/modules.html">the modules page</a> for more information)</li>
    <li> You will need to request GPU resources to run Topaz's Denoise function (see example below)</li>
    <li>Test data can be found in <code>${TOPAZ_TEST_DATA}</code>
</ul>
<P>

<a Name="int"></a><div class="heading">Interactive job</div>
<div class="nudgeblock"><a href="/docs/userguide.html#int">Interactive jobs</a> should be used for debugging, graphics, or applications that cannot be run as batch jobs.</div>
<p>Allocate an <a href="/docs/userguide.html#int">interactive session</a> and run the program. Sample session:</p>
<pre class="term">
[user@biowulf]$ <b>sinteractive --gres=gpu:k80:1,lscratch:50 --cpus-per-task=8 --mem=4g</b>
salloc.exe: Pending job allocation 46116226
salloc.exe: job 46116226 queued and waiting for resources
salloc.exe: job 46116226 has been allocated resources
salloc.exe: Granted job allocation 46116226
salloc.exe: Waiting for resource configuration
salloc.exe: Nodes cn4224 are ready for job

[user@cn4224 ~]$ <b>cd /lscratch/$SLURM_JOB_ID</b>
[user@cn4224 ~]$ <b>module load topaz/0.2.4</b>
[user@cn4224 ~]$ <b>cp ${TOPAZ_TEST_DATA}/topaz-tutorial-data.tar.gz .</b>
[user@cn4224 ~]$ <b>tar -xzf topaz-tutorial-data.tar.gz</b>
</pre>

<p>Preprocessing step:</p>
<pre class="term">
[user@cn4224 ~]$ <b>mkdir -p data/EMPIAR-10025/processed</b>
[user@cn4224 ~]$ <b>mkdir -p data/EMPIAR-10025/processed/micrographs</b>
[user@cn4224 ~]$ <b>topaz preprocess -d 0 -v -s 8 -o \ 
                      data/EMPIAR-10025/processed/micrographs/ \
                      data/EMPIAR-10025/rawdata/micrographs/*.mrc</b>
# processed: 14sep05c_c_00003gr_00014sq_00004hl_00004es_c
# processed: 14sep05c_c_00003gr_00014sq_00005hl_00003es_c
# processed: 14sep05c_c_00003gr_00014sq_00007hl_00004es_c
# processed: 14sep05c_c_00003gr_00014sq_00011hl_00003es_c
# processed: 14sep05c_c_00003gr_00015sq_00015hl_00002es_c
# processed: 14sep05c_c_00003gr_00018sq_00008hl_00003es_c
# processed: 14sep05c_c_00003gr_00018sq_00010hl_00005es_c
# processed: 14sep05c_c_00003gr_00020sq_00011hl_00002es_c
# processed: 14sep05c_c_00003gr_00020sq_00011hl_00004es_c
# processed: 14sep05c_c_00004gr_00031sq_00002hl_00002es_c
# processed: 14sep05c_c_00004gr_00031sq_00005hl_00002es_c
# processed: 14sep05c_c_00004gr_00031sq_00010hl_00002es_c
# processed: 14sep05c_c_00004gr_00032sq_00007hl_00003es_c
# processed: 14sep05c_c_00004gr_00032sq_00010hl_00003es_c
# processed: 14sep05c_c_00004gr_00032sq_00029hl_00005es_c
# processed: 14sep05c_c_00004gr_00032sq_00031hl_00002es_c
# processed: 14sep05c_c_00004gr_00032sq_00033hl_00005es_c
# processed: 14sep05c_c_00004gr_00032sq_00037hl_00002es_c
# processed: 14sep05c_c_00004gr_00032sq_00037hl_00003es_c
# processed: 14sep05c_c_00004gr_00032sq_00040hl_00002es_c
# processed: 14sep05c_c_00004gr_00032sq_00040hl_00004es_c
# processed: 14sep05c_c_00004gr_00032sq_00041hl_00005es_c
# processed: 14sep05c_c_00007gr_00013sq_00004hl_00003es_c
# processed: 14sep05c_c_00007gr_00013sq_00005hl_00002es_c
# processed: 14sep05c_c_00007gr_00013sq_00006hl_00002es_c
# processed: 14sep05c_c_00007gr_00013sq_00008hl_00003es_c
# processed: 14sep05c_c_00007gr_00013sq_00008hl_00004es_c
# processed: 14sep05c_c_00007gr_00013sq_00009hl_00002es_c
# processed: 14sep05c_c_00007gr_00013sq_00009hl_00004es_c
# processed: 14sep05c_c_00007gr_00013sq_00014hl_00004es_c

[user@cn4224 ~] <b>topaz convert -s 8 -o \
                      data/EMPIAR-10025/processed/particles.txt \
                      data/EMPIAR-10025/rawdata/particles.txt</b>
</pre>

<p>Training step:</p>
<pre class="term">
[user@cn4224 ~]$ <b>mkdir -p saved_models</b> 
[user@cn4224 ~]$ <b>mkdir -p saved_models/EMPIAR-10025</b>
[user@cn4224 ~]$ <b>topaz train -n 400 \
                       --num-workers=8 \
                       --train-images data/EMPIAR-10025/processed/micrographs/ \
                       --train-targets data/EMPIAR-10025/processed/particles.txt \
                       --save-prefix=saved_models/EMPIAR-10025/model \
                       -o saved_models/EMPIAR-10025/model_training.txt</b>
# Loading model: resnet8
# Model parameters: units=32, dropout=0.0, bn=on
# Loading pretrained model: resnet8_u32
# Receptive field: 71
# Using device=0 with cuda=True
# Loaded 30 training micrographs with 1500 labeled particles
# source	split	p_observed	num_positive_regions	total_regions
# 0	train	0.00163	43500	26669790
# Specified expected number of particle per micrograph = 400.0
# With radius = 3
# Setting pi = 0.0130484716977524
# minibatch_size=256, epoch_size=1000, num_epochs=10
# Done!
</pre>

<p>Extraction step:</p>
<pre class="term">
[user@cn4224 ~]$ <b>mkdir -p data/EMPIAR-10025/topaz</b>
[user@cn4224 ~]$ <b>topaz extract -r 14 -x 8 -m \
                       saved_models/EMPIAR-10025/model_epoch10.sav \
                       -o data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.txt \
                       data/EMPIAR-10025/processed/micrographs/*.mrc</b>
[user@cn4224 ~]$ <b>exit</b>
salloc.exe: Relinquishing job allocation 46116226
[user@biowulf ~]$
</pre>

<P>
<a Name="sbatch"></a><div class="heading">Batch job</div>
<div class="nudgeblock">Most jobs should be run as <A href="/docs/userguide.html#submit">batch jobs</a>.</div>
<p>Create a batch input file (e.g. topaz.sh) similar to the following.</p>

<pre class="term">
#! /bin/bash

set -e

module load topaz

topaz preprocess -d 0 -v -s 8 -o \ 
  data/EMPIAR-10025/processed/micrographs/ \
  data/EMPIAR-10025/rawdata/micrographs/*.mrc

topaz convert -s 8 -o \
  data/EMPIAR-10025/processed/particles.txt \
  data/EMPIAR-10025/rawdata/particles.txt

topaz train -n 400 \
  --num-workers=8 \
  --train-images data/EMPIAR-10025/processed/micrographs/ \
  --train-targets data/EMPIAR-10025/processed/particles.txt \
  --save-prefix=saved_models/EMPIAR-10025/model \
  -o saved_models/EMPIAR-10025/model_training.txt

topaz extract -r 14 -x 8 -m \
  saved_models/EMPIAR-10025/model_epoch10.sav \
  -o data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.txt \
  data/EMPIAR-10025/processed/micrographs/*.mrc
</pre>

<p>Submit these jobs using the Slurm <a href="/docs/userguide.html">sbatch</a> command.</p>

<a Name="swarm"></a><div class="heading">Swarm of Jobs </div>
<div class="nudgeblock">A <a href="/apps/swarm.html">swarm of jobs</a> is an easy way to submit a set of independent commands requiring identical resources.</div>

<p>Create a swarmfile for the first step of the pipeline (e.g. topaz.swarm). For example:</p>

<pre class="term">
topaz preprocess -d 0 -v -s 8 -o \ 
  dataset1/processed/micrographs/ \
  dataset1/rawdata/micrographs/*.mrc
topaz preprocess -d 0 -v -s 8 -o \ 
  dataset2/processed/micrographs/ \
  dataset2/rawdata/micrographs/*.mrc
topaz preprocess -d 0 -v -s 8 -o \ 
  dataset3/processed/micrographs/ \
  dataset3/rawdata/micrographs/*.mrc
</pre>

<p>Submit this job using the <a href='/apps/swarm.html'>swarm</a> command.</p>

<pre class="term">swarm -f topaz.swarm [-g #] --module topaz</pre>
where
<table border=0>
  <tr><td width=20%>-g # <td>Number of Gigabytes of memory required for each process (1 line in the swarm command file)
  <tr><td>--module topaz <td>Loads the topaz module for each subjob in the swarm
</table>




<!-- End content area - do not edit below this line -->
<script type="text/javascript" language="JavaScript" src='/js/footer.js'></script>
